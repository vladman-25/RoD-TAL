{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target experiments\n",
    "\n",
    "- [1] Q \n",
    "- [2] Q+A \n",
    "- [3] QA + rerank jina\n",
    "- [4] QA + rerank bert-msmarco\n",
    "- [5] QA rephrase with llama 3.1 8b\n",
    "- [6] QA rephrase with gpt 4o mini\n",
    "- [7] QA + finetune retriever\n",
    "- [8] QA + finetune retriever + reranker jina\n",
    "- [9] QA + augmented finetune retriever\n",
    "\n",
    "# Desired results\n",
    "- csv with question id, \"input\", retrieved documents (10 documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "\n",
    "class VectorStore():\n",
    "    def __init__(self, embedding_model: SentenceTransformer, rerank_model: CrossEncoder):\n",
    "        self.embedding_model = embedding_model\n",
    "        self.rerank_model = rerank_model\n",
    "        self.vector_store = []\n",
    "        self.embedding_matrix = None\n",
    "\n",
    "    def index_documents(self, documents):\n",
    "        # Encode and normalize all document embeddings\n",
    "        embeddings = self.embedding_model.encode(\n",
    "            [doc['payload'] for doc in documents],\n",
    "            convert_to_tensor=True,\n",
    "            normalize_embeddings=True\n",
    "        )\n",
    "\n",
    "        # Store each document along with its embedding\n",
    "        self.vector_store = []\n",
    "        for idx, embedding in enumerate(embeddings):\n",
    "            self.vector_store.append({\n",
    "                'id': documents[idx]['id'],\n",
    "                'payload': documents[idx]['payload'],\n",
    "                'vector': embedding  # keep it as a torch tensor\n",
    "            })\n",
    "\n",
    "        # Stack all embeddings into a single tensor for search\n",
    "        self.embedding_matrix = torch.stack([entry['vector'] for entry in self.vector_store])\n",
    "\n",
    "    def search(self, query, top_k=6):\n",
    "        # Encode and normalize the query\n",
    "        query_embedding = self.embedding_model.encode(\n",
    "            [query],\n",
    "            convert_to_tensor=True,\n",
    "            normalize_embeddings=True,\n",
    "            show_progress_bar=False\n",
    "        )  # shape: (1, dim)\n",
    "\n",
    "        # Compute cosine similarity (dot product of normalized vectors)\n",
    "        scores = torch.matmul(query_embedding, self.embedding_matrix.T)  # shape: (1, num_docs)\n",
    "\n",
    "        # Get top_k scores and corresponding indices\n",
    "        top_k_scores, top_k_indices = torch.topk(scores, k=top_k, dim=1)\n",
    "\n",
    "        # Retrieve top_k documents\n",
    "        top_k_documents = [self.vector_store[idx] for idx in top_k_indices[0].tolist()]\n",
    "\n",
    "        return top_k_documents, top_k_scores[0].tolist()\n",
    "\n",
    "    def rerank(self, query, top_k_documents, top_k=6):\n",
    "        scores = self.rerank_model.rank(\n",
    "            query=query,\n",
    "            documents=[doc['payload'] for doc in top_k_documents]\n",
    "        )\n",
    "        return [top_k_documents[idx['corpus_id']] for idx in scores][:top_k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/dataset_V3/corpus.csv\", index_col=\"id\")\n",
    "documents = []\n",
    "for idx, row in df.iterrows():\n",
    "    documents.append({\"id\": idx, \"payload\": f\"{row['title_metadata']} | {row['content']}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_merge_df():\n",
    "    splits = [\"1_train\", \"1_test\", \"2\"]\n",
    "\n",
    "    specs = [\n",
    "        # (model_display_name, base_path_with_{split})\n",
    "        (\"o4-mini (best reasoning)\", \"/Users/vladman/Desktop/university/driving-with-llms/results/qa/qa_strat_6_split_{}.csv\"),\n",
    "        (\"Mistral (worst)\",     \"/Users/vladman/Desktop/university/driving-with-llms/results/qa_vllm/qa_strat_4_split_{}_vllm.csv\"),\n",
    "        (\"Gemma (best open)\",         \"/Users/vladman/Desktop/university/driving-with-llms/results/qa_vllm2/qa_strat_4_split_{}_vllm.csv\"),\n",
    "    ]\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    for model_name, base in specs:\n",
    "        for split in splits:\n",
    "            base_path = base.format(split)\n",
    "            df = pd.read_csv(base_path)\n",
    "\n",
    "            sub = df[[\"id\", \"exact_match\", \"output_prompt\"]].copy()\n",
    "            sub.columns = [\"id\", \"exact_match\", \"output_prompt\"]\n",
    "            sub.insert(0, \"model\", model_name)\n",
    "            sub.insert(1, \"split\", split)\n",
    "\n",
    "            frames.append(sub)\n",
    "\n",
    "    agg = pd.concat(frames, ignore_index=True)\n",
    "    return agg\n",
    "\n",
    "df = load_merge_df()\n",
    "# Group by question ID and check if all models got it wrong\n",
    "wrong_ids = (\n",
    "    df.groupby(\"id\")[\"exact_match\"]\n",
    "    .apply(lambda x: (x == False).all())  # or: (~x).all()\n",
    ")\n",
    "\n",
    "# Filter the dataframe to only those IDs where all models were wrong\n",
    "df_all_wrong = df[df[\"id\"].isin(wrong_ids[wrong_ids].index)]\n",
    "\n",
    "wrong_ids = df_all_wrong[\"id\"].unique()\n",
    "print(len(wrong_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "import pytrec_eval\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from collections.abc import Callable, Awaitable\n",
    "import numpy as np\n",
    "\n",
    "def eval_ir_framework(dataset: pd.DataFrame, strategy: Callable, name: str, top_k_search=10):\n",
    "    print('='*30)\n",
    "    print(f\"{name}\")\n",
    "    print('='*30)\n",
    "\n",
    "    fnqrel = {}\n",
    "    fqrel = {}\n",
    "    frun = defaultdict(dict)\n",
    "\n",
    "    docs_retrieved = []\n",
    "\n",
    "    for idx, item in tqdm(dataset.iterrows()):\n",
    "        if item[\"id\"] not in wrong_ids:\n",
    "            continue\n",
    "        \n",
    "        articles = ast.literal_eval(item['legislation'])  # ground truth: list of relevant articles\n",
    "        question = item[\"question\"]  # the question for search\n",
    "        possible_answer = \" | \".join([entry['answer_text'] \n",
    "                                    for entry in ast.literal_eval(item['answers'])])\n",
    "        relevant_set = list(set(articles))\n",
    "\n",
    "        retrieved_set_1 = strategy(question, possible_answer, item['id'])\n",
    "        docs_retrieved.append(retrieved_set_1)\n",
    "        qrel = {}\n",
    "        for doc in relevant_set:\n",
    "            qrel[doc] = 1\n",
    "        \n",
    "        nqrel = {}\n",
    "        for doc in relevant_set:\n",
    "            nqrel[doc] = 2\n",
    "\n",
    "        fqrel[f'{idx}-query'] = qrel\n",
    "        fnqrel[f'{idx}-query'] = nqrel\n",
    "\n",
    "        for i in range(1, top_k_search+1):\n",
    "            run = {}\n",
    "            for doc, score in zip(retrieved_set_1[:i], [1 - 0.05 * x for x in range(10)]):\n",
    "                run[doc] = score\n",
    "            frun[str(i)][f'{idx}-query'] = run\n",
    "        \n",
    "        \n",
    "    recalls = []\n",
    "    precisions = []\n",
    "    ndcgs = []\n",
    "    for i in range(1, top_k_search+1):\n",
    "        evaluator = pytrec_eval.RelevanceEvaluator(fqrel, {f'recall.{i}'})\n",
    "        results = evaluator.evaluate(frun[str(i)])\n",
    "        avg_recall = np.mean([res[f'recall_{i}'] for res in list(results.values())])\n",
    "        # print(f\"Avg Recall@{i}: {avg_recall}\")\n",
    "        recalls.append(avg_recall.item())\n",
    "\n",
    "        evaluator = pytrec_eval.RelevanceEvaluator(fqrel, {f'P.{i}'})\n",
    "        results = evaluator.evaluate(frun[str(i)])\n",
    "        avg_precision = np.mean([res[f'P_{i}'] for res in list(results.values())])\n",
    "        # print(f\"Avg Precision@{i}: {avg_precision}\")\n",
    "        precisions.append(avg_precision.item())\n",
    "\n",
    "        evaluator = pytrec_eval.RelevanceEvaluator(fnqrel, {f'ndcg_cut.{i}', })\n",
    "        results = evaluator.evaluate(frun[str(i)])\n",
    "        avg_ndcg = np.mean([res[f'ndcg_cut_{i}'] for res in list(results.values())])\n",
    "        # print(f\"Avg NDCG@{i}: {avg_ndcg}\")\n",
    "        ndcgs.append(avg_ndcg.item())\n",
    "    \n",
    "\n",
    "    # dataset['retrieved_documents'] = docs_retrieved\n",
    "\n",
    "    return recalls, precisions, ndcgs, None\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_simple = VectorStore(SentenceTransformer('intfloat/multilingual-e5-small') , None)\n",
    "vector_store_simple.index_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_finetuned = VectorStore(SentenceTransformer('../models/data_trained_V2') , None)\n",
    "vector_store_finetuned.index_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_finetuned_jina = VectorStore(SentenceTransformer('../models/data_trained_V2') , CrossEncoder(\"jinaai/jina-reranker-v2-base-multilingual\",\n",
    "                            automodel_args={\"torch_dtype\": \"auto\"},\n",
    "                            trust_remote_code=True))\n",
    "vector_store_finetuned_jina.index_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_jina = VectorStore(SentenceTransformer('intfloat/multilingual-e5-small') , CrossEncoder(\"jinaai/jina-reranker-v2-base-multilingual\",\n",
    "                            automodel_args={\"torch_dtype\": \"auto\"},\n",
    "                            trust_remote_code=True))\n",
    "vector_store_jina.index_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_bertms = VectorStore(SentenceTransformer('intfloat/multilingual-e5-small') , CrossEncoder(\"amberoad/bert-multilingual-passage-reranking-msmarco\"))\n",
    "vector_store_bertms.index_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_finetuned_augmented = VectorStore(SentenceTransformer('../models/augmented_V2') , None)\n",
    "vector_store_finetuned_augmented.index_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt_rephrased = pd.read_csv('../results/results-ir-question-rephrase-gpt-4o-mini.csv')\n",
    "\n",
    "def strategy_1(question, possible_answer, id):\n",
    "    top_k_documents, top_k_scores = vector_store_simple.search(f\"{question}\", top_k=10)\n",
    "    retrieved_set = [doc['id'] for doc in top_k_documents]\n",
    "    return retrieved_set\n",
    "\n",
    "def strategy_2(question, possible_answer, id):\n",
    "    top_k_documents, top_k_scores = vector_store_simple.search(f\"{question} | {possible_answer}\", top_k=10)\n",
    "    retrieved_set = [doc['id'] for doc in top_k_documents]\n",
    "    return retrieved_set\n",
    "\n",
    "def strategy_3(question, possible_answer, id):\n",
    "    top_k_documents, top_k_scores = vector_store_jina.search(f\"{question} | {possible_answer}\", top_k=40)\n",
    "    top_k_documents = vector_store_jina.rerank(f\"{question} | {possible_answer}\", top_k_documents, top_k=10)\n",
    "    retrieved_set = [doc['id'] for doc in top_k_documents]\n",
    "    return retrieved_set\n",
    "\n",
    "def strategy_4(question, possible_answer, id):\n",
    "    top_k_documents, top_k_scores = vector_store_bertms.search(f\"{question} | {possible_answer}\", top_k=40)\n",
    "    sentences = [\n",
    "        [f\"{question} | {possible_answer}\", doc['payload']]\n",
    "        for doc in top_k_documents]\n",
    "        \n",
    "    res = vector_store_bertms.rerank_model.predict(sentences)\n",
    "    relevant_scores = [score[1] for score in res]\n",
    "    doc_score_pairs = list(zip(top_k_documents, relevant_scores))\n",
    "    doc_score_pairs.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_docs = doc_score_pairs[:10]\n",
    "    retrieved_set = [doc['id'] for doc, score in top_docs]\n",
    "    return retrieved_set\n",
    "\n",
    "def strategy_6(question, possible_answer, id):\n",
    "    rephrased_question = df_gpt_rephrased.loc[df_gpt_rephrased['id'] == id, 'rephrased_query'].values[0]\n",
    "    top_k_documents, top_k_scores = vector_store_simple.search(f\"{rephrased_question} | {possible_answer}\", top_k=40)\n",
    "    retrieved_set = [doc['id'] for doc in top_k_documents]\n",
    "    return retrieved_set\n",
    "\n",
    "def strategy_7(question, possible_answer, id):\n",
    "    top_k_documents, top_k_scores = vector_store_finetuned.search(f\"{question} | {possible_answer}\", top_k=10)\n",
    "    retrieved_set = [doc['id'] for doc in top_k_documents]\n",
    "    return retrieved_set\n",
    "\n",
    "def strategy_8(question, possible_answer, id):\n",
    "    top_k_documents, top_k_scores = vector_store_finetuned_jina.search(f\"{question} | {possible_answer}\", top_k=40)\n",
    "    top_k_documents = vector_store_finetuned_jina.rerank(f\"{question} | {possible_answer}\", top_k_documents, top_k=10)\n",
    "    retrieved_set = [doc['id'] for doc in top_k_documents]\n",
    "    return retrieved_set\n",
    "\n",
    "def strategy_9(question, possible_answer, id):\n",
    "    top_k_documents, top_k_scores = vector_store_finetuned_augmented.search(f\"{question} | {possible_answer}\", top_k=10)\n",
    "    retrieved_set = [doc['id'] for doc in top_k_documents]\n",
    "    return retrieved_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_split_1_train = pd.read_csv('../data/dataset_V3/split_1_train.csv')\n",
    "df_split_1_test = pd.read_csv('../data/dataset_V3/split_1_test.csv')\n",
    "recalls, precisions, ndcgs, retrieved = eval_ir_framework(df_split_1_train, strategy_1, '1-train')\n",
    "print(recalls)\n",
    "print(precisions)\n",
    "print(ndcgs)\n",
    "retrieved.to_csv('../results/ir_strat_1_train.csv', index=False)\n",
    "recalls, precisions, ndcgs, retrieved = eval_ir_framework(df_split_1_test, strategy_1, '1-test')\n",
    "print(recalls)\n",
    "print(precisions)\n",
    "print(ndcgs)\n",
    "retrieved.to_csv('../results/ir_strat_1_test.csv', index=False)\n",
    "##########################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_split_1_train = pd.read_csv('../data/dataset_V3/split_1_train.csv')\n",
    "df_split_1_test = pd.read_csv('../data/dataset_V3/split_1_test.csv')\n",
    "recalls, precisions, ndcgs, retrieved = eval_ir_framework(df_split_1_train, strategy_2, '2-train')\n",
    "print(recalls)\n",
    "print(precisions)\n",
    "print(ndcgs)\n",
    "retrieved.to_csv('../results/ir_strat_2_train.csv', index=False)\n",
    "recalls, precisions, ndcgs, retrieved = eval_ir_framework(df_split_1_test, strategy_2, '2-test')\n",
    "print(recalls)\n",
    "print(precisions)\n",
    "print(ndcgs)\n",
    "retrieved.to_csv('../results/ir_strat_2_test.csv', index=False)\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_split_1_train = pd.read_csv('../data/dataset_V3/split_1_train.csv')\n",
    "df_split_1_test = pd.read_csv('../data/dataset_V3/split_1_test.csv')\n",
    "recalls, precisions, ndcgs, retrieved = eval_ir_framework(df_split_1_train, strategy_3, '3-train')\n",
    "print(recalls)\n",
    "print(precisions)\n",
    "print(ndcgs)\n",
    "retrieved.to_csv('../results/ir_strat_3_train.csv', index=False)\n",
    "recalls, precisions, ndcgs, retrieved = eval_ir_framework(df_split_1_test, strategy_3, '3-test')\n",
    "print(recalls)\n",
    "print(precisions)\n",
    "print(ndcgs)\n",
    "retrieved.to_csv('../results/ir_strat_3_test.csv', index=False)\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_split_1_train = pd.read_csv('../data/dataset_V3/split_1_train.csv')\n",
    "df_split_1_test = pd.read_csv('../data/dataset_V3/split_1_test.csv')\n",
    "recalls, precisions, ndcgs, retrieved = eval_ir_framework(df_split_1_train, strategy_4, '4-train')\n",
    "print(recalls)\n",
    "print(precisions)\n",
    "print(ndcgs)\n",
    "retrieved.to_csv('../results/ir_strat_4_train.csv', index=False)\n",
    "recalls, precisions, ndcgs, retrieved = eval_ir_framework(df_split_1_test, strategy_4, '4-test')\n",
    "print(recalls)\n",
    "print(precisions)\n",
    "print(ndcgs)\n",
    "retrieved.to_csv('../results/ir_strat_4_test.csv', index=False)\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_split_1_train = pd.read_csv('../data/dataset_V3/split_1_train.csv')\n",
    "df_split_1_test = pd.read_csv('../data/dataset_V3/split_1_test.csv')\n",
    "recalls, precisions, ndcgs, retrieved = eval_ir_framework(df_split_1_train, strategy_6, '6-train')\n",
    "print(recalls)\n",
    "print(precisions)\n",
    "print(ndcgs)\n",
    "retrieved.to_csv('../results/ir_strat_6_train.csv', index=False)\n",
    "recalls, precisions, ndcgs, retrieved = eval_ir_framework(df_split_1_test, strategy_6, '6-test')\n",
    "print(recalls)\n",
    "print(precisions)\n",
    "print(ndcgs)\n",
    "retrieved.to_csv('../results/ir_strat_6_test.csv', index=False)\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "7-train\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "510it [00:00, 1485.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "==============================\n",
      "7-test\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "128it [00:00, 4410.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_split_1_train = pd.read_csv('../data/dataset_V3/split_1_train.csv')\n",
    "df_split_1_test = pd.read_csv('../data/dataset_V3/split_1_test.csv')\n",
    "recalls, precisions, ndcgs, retrieved = eval_ir_framework(df_split_1_train, strategy_7, '7-train')\n",
    "print(recalls[9])\n",
    "# retrieved.to_csv('../results/ir_strat_7_b_train.csv', index=False)\n",
    "recalls, _, _, _ = eval_ir_framework(df_split_1_test, strategy_7, '7-test')\n",
    "print(recalls[9])\n",
    "# retrieved.to_csv('../results/ir_strat_7_b_test.csv', index=False)\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_split_1_train = pd.read_csv('../data/dataset_V3/split_1_train.csv')\n",
    "df_split_1_test = pd.read_csv('../data/dataset_V3/split_1_test.csv')\n",
    "recalls, precisions, ndcgs, retrieved = eval_ir_framework(df_split_1_train, strategy_8, '8-train')\n",
    "print(recalls)\n",
    "print(precisions)\n",
    "print(ndcgs)\n",
    "retrieved.to_csv('../results/ir_strat_8_train.csv', index=False)\n",
    "recalls, precisions, ndcgs, retrieved = eval_ir_framework(df_split_1_test, strategy_8, '8-test')\n",
    "print(recalls)\n",
    "print(precisions)\n",
    "print(ndcgs)\n",
    "retrieved.to_csv('../results/ir_strat_8_test.csv', index=False)\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_split_1_train = pd.read_csv('../data/dataset_V3/split_1_train.csv')\n",
    "df_split_1_test = pd.read_csv('../data/dataset_V3/split_1_test.csv')\n",
    "recalls, precisions, ndcgs, retrieved = eval_ir_framework(df_split_1_train, strategy_9, '9-train')\n",
    "print(recalls)\n",
    "print(precisions)\n",
    "print(ndcgs)\n",
    "retrieved.to_csv('../results/ir_strat_9_train.csv', index=False)\n",
    "recalls, precisions, ndcgs, retrieved = eval_ir_framework(df_split_1_test, strategy_9, '9-test')\n",
    "print(recalls)\n",
    "print(precisions)\n",
    "print(ndcgs)\n",
    "retrieved.to_csv('../results/ir_strat_9_test.csv', index=False)\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_split_1 = pd.read_csv('../data/dataset_V3/split_1.csv')\n",
    "# seed = 42\n",
    "# np.random.seed(seed)\n",
    "# shuffled_df = df_split_1.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "# train_size = int(0.8 * len(shuffled_df))\n",
    "# df_split_1_train = shuffled_df[:train_size]\n",
    "# df_split_1_test = shuffled_df[train_size:]\n",
    "\n",
    "\n",
    "# df_split_1_train.to_csv('../data/dataset_V3/split_1_train.csv', index=False)\n",
    "# df_split_1_test.to_csv('../data/dataset_V3/split_1_test.csv', index=False)\n",
    "\n",
    "# recalls, precisions, ndcgs = eval_ir_framework(df_split_1_train, strategy_2, '2-train')\n",
    "# print(recalls)\n",
    "# print(precisions)\n",
    "# print(ndcgs)\n",
    "\n",
    "# recalls, precisions, ndcgs = eval_ir_framework(df_split_1_test, strategy_2, '2-test')\n",
    "# print(recalls)\n",
    "# print(precisions)\n",
    "# print(ndcgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Count the occurrences of each category\n",
    "category_counts = df_split_1_train['question_category_id'].value_counts().sort_index()\n",
    "\n",
    "# Display counts\n",
    "print(category_counts)\n",
    "\n",
    "# Plot the distribution as a bar chart\n",
    "category_counts.plot(kind='bar')\n",
    "plt.xlabel('Question Category ID')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Question Categories')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_counts = df_split_1_test['question_category_id'].value_counts().sort_index()\n",
    "\n",
    "# Display counts\n",
    "print(category_counts)\n",
    "\n",
    "# Plot the distribution as a bar chart\n",
    "category_counts.plot(kind='bar')\n",
    "plt.xlabel('Question Category ID')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Question Categories')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate queries using LLM - save for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_ir = \"\"\"Esti un politist rutier. Vorbesti doar Limba romana.\n",
    "Primesti o grila de la un test auto, alaturi de raspunsurile posibile.\n",
    "Scopul tau este sa generezi o singura intrebare astfel incat sa poti cauta legile care fac referinta la intrebarea primita.\n",
    "\n",
    "Raspunsul tau se va incheia cu:\n",
    "\n",
    "\"Raspuns final: [intrebare generata tip string]\"\n",
    "\n",
    "Aceasta este intrebarea:\n",
    "{question}\n",
    "\n",
    "Aceastea sunt variantele de raspuns:\n",
    "{answers}\n",
    "===================\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import base64\n",
    "from langchain_core.messages import HumanMessage\n",
    "import asyncio\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "llm_gepeto = ChatOpenAI(model_name=\"gpt-4o-mini\", api_key=\"\", seed=25)\n",
    "\n",
    "MAX_CONCURRENT_REQUESTS = 45\n",
    "semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)\n",
    "\n",
    "async def process_item(full_prompt):\n",
    "    message = HumanMessage(\n",
    "        content=[\n",
    "            {\"type\": \"text\", \"text\": full_prompt},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    async with semaphore:\n",
    "        res = await llm_gepeto.ainvoke([message])\n",
    "        res = res.content\n",
    "    \n",
    "    return res\n",
    "\n",
    "async def mass_runner(data: pd.DataFrame):\n",
    "    tasks = []\n",
    "    for real_idx, (idx, item) in tqdm(enumerate(data.iterrows())):\n",
    "        # Create tasks for parallel processing\n",
    "        answers = \" | \".join([entry['answer_text'] \n",
    "                                    for entry in ast.literal_eval(item['answers'])])\n",
    "        tasks.append(process_item(prompt_ir.format(question=item['question'], answers=answers)))\n",
    "    \n",
    "    results = await asyncio.gather(*tasks)\n",
    "    final = []\n",
    "    for result, (idx, item) in zip(results, data.iterrows()):\n",
    "        result = result.split('final:')[-1].strip()\n",
    "        final.append(result)\n",
    "\n",
    "    data['rephrased_query'] = final\n",
    "\n",
    "    final_df = data[[\"id\",\"rephrased_query\"]]\n",
    "    return final_df\n",
    "\n",
    "df1 = pd.read_csv('../data/dataset_V3/split_1.csv')\n",
    "\n",
    "results = await mass_runner(df1)\n",
    "results.to_csv('../results/results-ir-question-rephrase-gpt-4o-mini.csv')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm_ollama = ChatOllama(\n",
    "    model = \"llama3.1:8b-instruct-q8_0\",\n",
    "    temperature = 0,\n",
    "    seed=25\n",
    ")\n",
    "\n",
    "def process_item_ollama(full_prompt):\n",
    "    message = [('human', full_prompt)]\n",
    "\n",
    "    res = llm_ollama.invoke(message)\n",
    "    return res\n",
    "\n",
    "res = process_item_ollama(\"\"\"\"Esti un politist rutier. Vorbesti doar in limba romana.\n",
    "Trebuie sa rezolvi o grila de la un test auto. Grila poate avea unul sau mai multe raspunsuri corecte. Vei folosi strict legile din Romania.\n",
    "\n",
    "Gandeste logic, dar nu extrapola peste informatiile oferite. Judeca doar momentul descris, nu presupune alte situatii.\n",
    "\n",
    "Reguli de gandire:\n",
    "1. Citeste cu maxima atentie intrebarea si variantele de raspuns.\n",
    "2. Identifica strict ce prevederi din legislatia rutiera din Romania se aplica situatiei date.\n",
    "3. Daca raspunsul pare \"\"mai sigur\"\" dar este contrar legislatiei, urmeaza legea, nu instinctul de precautie.\n",
    "4. Alege DOAR raspunsurile care sunt complet corecte conform textului legii — nu ghici, nu completa informatii lipsa.\n",
    "5. Daca un raspuns corect este mai bun decat altul dat ca si corect, include mai multe situatii specifice sau exceptii, atunci trebuie ales doar acela.\n",
    "6. Argumenteaza clar de ce ai ales fiecare raspuns corect. Daca exista mai multe raspunsuri corecte, explica fiecare alegere separat.\n",
    "7. Fii atent la mici detalii care pot schimba sensul intrebarii sau al raspunsurilor (exista intrebari-capcana).\n",
    "\n",
    "\n",
    "La final, ultima parte din raspuns trebuie sa fie litera sau literele corecte.\n",
    "De exemplu, raspunsul tau se va incheia cu:\n",
    "\n",
    "\"\"Raspuns corect: A\"\"  \n",
    "sau  \n",
    "\"\"Raspuns corect: A,B\"\"\n",
    "\n",
    "Aceasta este intrebarea:\n",
    "În care dintre situații depășirea este interzisă?\n",
    "\n",
    "Acestea sunt variantele de raspuns:\n",
    "A în intersecțiile cu circulație nedirijată și la trecerile pentru pietoni semnalizate; | B în intersecții și la o distanță de 50 m de acestea; | C în zona de acțiune a indicatorului „Limitare de viteză“.\n",
    "\n",
    "Aceastea sunt legile relevante, dar nu neaparat toate sunt relevante:\n",
    "[Regulament-118]: Reguli de circulație |  Reguli pentru circulația vehiculelor | Conducătorul de vehicul care efectuează depășirea este obligat: a)   să se asigure că acela care îl urmează sau îl precedă nu a semnalizat intenția începerii unei manevre similare și că poate depăși fără a pune în pericol sau fără a stânjeni circulația din sens opus;    b)   să semnalizeze intenția de efectuare a depășirii;    c)   să păstreze în timpul depășirii o distanță laterală suficienta față de vehiculul depășit;    d)   să reintre pe banda sau în șirul de circulație inițial după ce a semnalizat și s-a asigurat că poate efectua această manevră în condiții de siguranță pentru vehiculul depășit și pentru ceilalți participanți la trafic.   \n",
    "\n",
    "[Regulament-120]: Reguli de circulație |  Reguli pentru circulația vehiculelor | (1)   Se interzice depășirea vehiculelor: a)   în intersecții cu circulația nedirijată;    b)   în apropierea vârfurilor de rampa, când vizibilitatea este redusă sub 50 m;    c)   în curbe și în orice alte locuri unde vizibilitatea este redusă sub 50 m;    d)   pe pasaje denivelate, pe poduri, sub poduri și în tuneluri. Prin excepție, pot fi depășite în aceste locuri vehiculele cu tracțiune animală, motocicletele fără ataș, mopedele și bicicletele, dacă vizibilitatea asupra drumului este asigurată pe o distanță mai mare de 20 m, iar lățimea drumului este de cel puțin 7 m;    e)   pe trecerile pentru pietoni semnalizate prin indicatoare și marcaje;    f)   pe trecerile la nivel cu calea ferată curentă și la mai puțin de 50 m înainte de acestea;    g)   în dreptul stației pentru tramvai, atunci când acesta este oprit, iar stația nu este prevăzută cu refugiu pentru pietoni;    h)   în zona de acțiune a indicatorului \"\"Depășirea interzisă\"\";    i)   când pentru efectuarea manevrei se încalcă marcajul continuu, simplu sau dublu, care desparte sensurile de mers, iar autovehiculul circulă, chiar și parțial, pe sensul opus, ori se încalcă marcajul care delimitează spațiul de interzicere;    j)   când din sens opus se apropie un alt vehicul, iar conducătorul acestuia este obligat să efectueze manevre de evitare a coliziunii;    k)   pe sectorul de drum unde s-a format o coloana de vehicule în așteptare, dacă prin aceasta se intră pe sensul opus de circulație.    (2)   Se interzice depășirea coloanei oficiale.\n",
    "\n",
    "[OUG-55]: Reguli de circulație |  Reguli pentru circulația vehiculelor | Intersecțiile sunt: a)   cu circulație nedirijată;    b)   cu circulație dirijată. În aceasta categorie sunt incluse și intersecțiile în care circulația se desfășoară în sens giratoriu.   \n",
    "\n",
    "[Regulament-119]: Reguli de circulație |  Reguli pentru circulația vehiculelor | Conducătorul de vehicul care urmează să fie depășit este obligat: a)   să nu mărească viteza de deplasare;    b)   să circule cât mai aproape de marginea din dreapta a părții carosabile sau a benzii pe care se deplasează.   \n",
    "\n",
    "[OUG-51]: Reguli de circulație |  Reguli pentru circulația vehiculelor | Conducătorul unui vehicul care circulă în spatele altuia are obligația de a păstra o distanță suficientă față de acesta, pentru evitarea coliziunii.\n",
    "\n",
    "[OUG-45]: Reguli de circulație |  Reguli pentru circulația vehiculelor | (1)   Depășirea este manevra prin care un vehicul trece înaintea altui vehicul ori pe lângă un obstacol, aflat pe același sens de circulație, prin schimbarea direcției de mers și ieșirea de pe banda de circulație sau din șirul de vehicule în care s-a aflat inițial. (2)   Conducătorul vehiculului care se angajează în depășire trebuie să se asigure că vehiculul care circulă în fața sau în spatele lui nu a inițiat o asemenea manevră. (3)   Atunci când prin manevra de depășire se trece peste axa care separa sensurile de circulație, conducătorii de vehicule trebuie să se asigure că din sens opus nu se apropie un vehicul și că dispun de spațiu suficient pentru a reintra pe banda inițială, unde au obligația să revină după efectuarea manevrei de depășire. (4)   Nu constituie depășire, în sensul  alin. (1) , situația în care un vehicul circulă mai repede pe una dintre benzi decât vehiculele care circulă pe altă bandă în același sens de circulație. (5)   Depășirea se efectuează numai pe partea stângă a vehiculului depășit. Tramvaiul sau vehiculul al cărui conducător a semnalizat intenția și s-a încadrat corespunzător părăsirii sensului de mers spre stânga se depășește prin partea dreapta. (6)   Tramvaiul aflat în mers poate fi depășit și pe partea stângă atunci când drumul este cu sens unic sau când între șina din dreapta și marginea trotuarului nu există spațiu suficient.\n",
    "\n",
    "[Regulament-135]: Reguli de circulație |  Reguli pentru circulația vehiculelor | Conducătorul de vehicul este obligat să acorde prioritate de trecere și în următoarele situații: a)   la intersecția nedirijată atunci când pătrunde pe un drum național venind de pe un drum județean, comunal sau local;    b)   la intersecția nedirijată atunci când pătrunde pe un drum județean venind de pe un drum comunal sau local;    c)   la intersecția nedirijată atunci când pătrunde pe un drum comunal venind de pe un drum local;    d)   când urmează să pătrundă într-o intersecție cu circulație în sens giratoriu față de cel care circulă în interiorul acesteia;    e)   când circulă în panta față de cel care urca, dacă pe sensul de mers al celui care urca se află un obstacol imobil. În această situație manevra nu este considerată depășire în sensul prevederilor  art. 120 lit. j) ;    f)   când se pune în mișcare sau la pătrunderea pe drumul public venind de pe o proprietate alăturată acestuia față de vehiculul care circulă pe drumul public, indiferent de direcția de deplasare;    g)   când efectuează un viraj spre stânga sau spre dreapta și se intersectează cu un biciclist care circulă pe o pistă pentru biciclete, semnalizată ca atare;    h)   pietonului care traversează drumul public, prin loc special amenajat, marcat și semnalizat corespunzător ori la culoarea verde a semaforului destinat lui, atunci când acesta se află pe sensul de mers al vehiculului.   \n",
    "\n",
    "[Regulament-107]: Reguli de circulație |  Reguli pentru circulația vehiculelor | (1)   La intersecțiile prevăzute cu indicatoare și/sau cu marcaje pentru semnalizarea direcției de mers, conducătorii de vehicule trebuie să se încadreze pe benzile corespunzătoare direcției de mers voite cu cel puțin 50 m înainte de intersecție și sunt obligați să respecte semnificația indicatoarelor și marcajelor. (2)   La intersecțiile fără marcaje de delimitare a benzilor, conducătorii vehiculelor ocupa în mers, cu cel puțin 50 m înainte de intersecție, următoarele poziții: a)   rândul de lângă bordura sau acostament, cei care vor să schimbe direcția de mers spre dreapta;    b)   rândul de lângă axa drumului sau de lângă marcajul de separare a sensurilor, cei care vor să schimbe direcția de mers spre stânga. Când circulația se desfășoară pe drumuri cu sens unic, conducătorii de vehicule care intenționează să vireze la stânga sunt obligați să ocupe rândul de lângă bordura sau acostamentul din partea stânga;    c)   oricare dintre rânduri, cei care vor să meargă înainte.    (3)   Dacă în intersecție circulă și tramvaie, iar spațiul dintre șina din dreapta și trotuar nu permite circulația pe două sau mai multe rânduri, toți conducătorii de vehicule, indiferent de direcția de deplasare, vor circula pe un singur rând, lăsând liber traseul tramvaiului. (4)   În cazul în care tramvaiul este oprit într-o stație fără refugiu pentru pietoni, vehiculele trebuie să oprească în ordinea sosirii, în spatele acestuia, și să își reia deplasarea numai după ce ușile tramvaiului au fost închise și s-au asigurat că nu pun în pericol siguranța pietonilor angajați în traversarea drumului public.\n",
    "\n",
    "[Regulament-114]: Reguli de circulație |  Reguli pentru circulația vehiculelor | (1)   Conducătorii de autovehicule și tramvaie sunt obligați să folosească instalațiile de iluminare și/sau semnalizare a acestora, după cum urmează: ----------- Partea introductivă a alin. (1) al art. 114 a fost modificată de pct. 15 al  , publicată în MONITORUL OFICIAL nr. 454 din 24 iulie 2013. a)   luminile de poziție sau de staționare pe timpul imobilizării vehiculului pe partea carosabilă în afara localităților, de la lăsarea serii și până în zorii zilei, ziua când plouă torențial, ninge abundent sau este ceață densă ori în alte condiții care reduc vizibilitatea pe drumul public;    b)   luminile de întâlnire sau de drum, în mers, atât în localități, cât și în afara acestora, după gradul de iluminare a drumului public;    c)   luminile de întâlnire și cele de ceață pe timp de ceață densă;    d)   luminile de întâlnire ale autovehiculelor care însoțesc coloane militare sau cortegii, transporta grupuri organizate de persoane și cele care tractează alte vehicule sau care transporta mărfuri ori produse periculoase, în timpul zilei;    e)   luminile de întâlnire atunci când plouă torențial, ninge abundent ori în alte condiții care reduc vizibilitatea pe drum;    f)   luminile pentru mersul înapoi atunci când vehiculul este manevrat către înapoi;    g)   luminile indicatoare de direcție pentru semnalizarea schimbării direcției de mers, inclusiv la punerea în mișcare a vehiculului de pe loc.    (2)   Pe timpul nopții, la apropierea a două vehicule care circulă din sensuri opuse, conducătorii acestora sunt obligați ca de la o distanță de cel puțin 200 m să folosească luminile de întâlnire concomitent cu reducerea vitezei. Când conducătorul de autovehicul se apropie de un autovehicul care circulă în față să, acesta este obligat să folosească luminile de întâlnire de la o distanță de cel puțin 100 m. (3)   Pe timpul nopții sau în condiții de vizibilitate redusă conducătorii de autovehicule și tramvaie care se apropie de o intersecție nedirijată prin semnale luminoase sau de către polițiști sunt obligați să semnalizeze prin folosirea alternantă a luminilor de întâlnire cu cele de drum dacă nu încalcă astfel prevederile  alin. (2) . (4)   Pe timpul nopții sau în condiții de vizibilitate redusă autovehiculele sau remorcile cu defecțiuni la sistemul de iluminare și semnalizare luminoasă nu pot fi conduse sau remorcate fără a avea în funcțiune pe partea stânga, în față o lumină de întâlnire și în spate una de poziție. (5)   Luminile de avarie se folosesc în următoarele situații: a)   când vehiculul este imobilizat involuntar pe partea carosabilă;    b)   când vehiculul se deplasează foarte lent și/sau constituie el însuși un pericol pentru ceilalți participanți la trafic;    c)   când autovehiculul sau tramvaiul este remorcat.    (6)   În situațiile prevăzute la  alin. (5) , conducătorii de autovehicule și tramvaie trebuie să pună în funcțiune luminile de avarie, în mod succesiv, în ordinea opririi și în cazul în care această manevră este impusă de blocarea circulației pe sensul de mers. \n",
    "\t\t\t\t (7)   Când circulă prin tunel conducătorul de vehicul este obligat să folosească luminile de întâlnire.\n",
    "\n",
    "[OUG-54]: Reguli de circulație |  Reguli pentru circulația vehiculelor | (1)   Conducătorul de vehicul care executa o manevra de schimbare a direcției de mers, de ieșire dintr-un rând de vehicule staționate sau de intrare într-un asemenea rând, de trecere pe o altă bandă de circulație sau de virare spre dreapta ori spre stânga sau care urmează să efectueze o întoarcere ori să meargă cu spatele este obligat să semnalizeze din timp și să se asigure că o poate face fără să perturbe circulația sau să pună în pericol siguranța celorlalți participanți la trafic. (2)   Semnalizarea schimbării direcției de mers trebuie să fie menținută pe întreaga durată a manevrei.\n",
    "===================\"\"\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_3 = {\n",
    "    'recalls': [0.3673763497039359, 0.4715112952181918, 0.5257625516246205, 0.5699899238692343, 0.5947373986167089, 0.6251977907150321, 0.6506232273473653, 0.6653517938000696, 0.6761836343732895, 0.689818754042892],\n",
    "    'precisions': [0.6990595611285266, 0.4882445141065831, 0.3777429467084639, 0.31739811912225707, 0.2699059561128527, 0.24164054336468127, 0.2165248544558889, 0.19553291536050157, 0.178335074886799, 0.1652037617554859],\n",
    "    'ndcgs': [0.6990595611285266, 0.6097307413952153, 0.5914752236503356, 0.5974592084870567, 0.6028588794957924, 0.6149046138206468, 0.6242005379014265, 0.6305268473398761, 0.6353666716174842, 0.6410628986256416]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_4 = {\n",
    "    'recalls': [0.2903225605811813, 0.4005056724884311, 0.45978317659352136, 0.505028735632184, 0.5360258993879683, 0.5650756331790814, 0.5871921182266009, 0.6097203562720803, 0.6249303378613723, 0.6432166492511319],\n",
    "    'precisions': [0.5579937304075235, 0.4169278996865204, 0.33176593521421105, 0.28056426332288403, 0.24231974921630092, 0.2173458725182863, 0.19547693685624717, 0.1786833855799373, 0.16440264716126787, 0.15282131661442008],\n",
    "    'ndcgs': [0.5579937304075235, 0.509001724856592, 0.502477113472332, 0.5105194488495042, 0.5202249975565368, 0.5319279322038794, 0.5403551242672291, 0.5494783435386795, 0.5558664659802995, 0.5628200221958617]\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
